## 前言
在前两个章节我们学习了如何从文件中读取并导入数据。当我们导入完数据以后，面临的第一项重要的任务就是数据的预处理，包括数据基本信息查看、缺失值处理和重复值处理等。
## 熟悉数据
本节重点介绍如何查看数据的相关信息，对于一个数据分析师来说，进行数据分析前对数据有一定的了解可以大大提高后续工作的效率。
学习过第一章的读者可能知道在pandas库中有一个方法可以查看DataFrame的数据基本类型，也提到过一个DataFrame相当于一张Excel中的一张工作表，那位迷人的函数是谁呢？请回想一下，也可以顺便回去复习一下。是的，他就是我们人见人爱的`info`小姐。
这里我们可以再用第二章获得的数据来使用一次`info`函数，其实该函数不仅仅是对Excel表，其是对一个数据集生效的，当处理大型数据集时，该函数能帮助我们快速了解数据的基本情况，以便我们识别可能需要处理的数据问题。
```python
import pandas as pd
df=pd.read_csv("stockA.csv")
df.info()
```
然后我们可以看到以下内容：
![firstresult](https://i.postimg.cc/T1bc0hgF/image.png)
从输出结果中我们可以看出，info方法返回了数据表的行数为11行(RangeIndex)，列数(columns)为5，同时返回了每一列数据中的非空值个数(Non-Null Count)和数据类型(dtypes)以及内存使用情况(memory usage)。
这里作者提出一个问题，如果我们想知道数据表的尺寸该使用哪个函数呢？请根据英文含义来联想，一般来说Python语言中的函数大部分是英文单词本身。
在shape方法中，我们可以用shape[0]来查看数据表的行数，shape[1]查看数据表的列数，单独的shape（不带括号）生成一个带有行数和列数的元组。例子如下所示，请自己运行一下查看结果。
```python
import pandas as pd
df1=pd.read_csv("stockA.csv")
df1.shape[0]
df1.shape[1]
df1.shape
```
这里作者再考考读者，请根据第一章的知识动手做一下，请问如何使用Python生成1行3列的DataFrame类型数据df和数据组类型arr，且要求二者数值的取值范围在4~8之间，df的列名为a，b，c，最后返回df和arr的数据类型。学习过Python应该有学相应的函数吧(-^-)，而且前面也提到了Python语言中的函数大部分是英文单词本身。实在不知道就提示一下，`type`。
```python
import pandas as pd
import numpy as np
df=pd.DataFrame(np.random.randint(4,8,size=(1,3)), columns=['a','b','c'])
arr=np.random.randint(4,8,size=(1,3))
print('df的数据类型为：')
print(type(df))
print('arr的数据类型为：')
print(type(arr))
```
可得以下输出结果：
![secondresult](https://i.postimg.cc/9f3wP1Jm/image.png)
在上例代码的基础之上，对于series数据可以使用`.dtype`对其数据格式进行查看，dataframe数据可以使用`.dtypes`进行查看，这里我们需要仔细观察两者的区别，注意嗷，一个带有“s”，一个没有“s”。这里作者就不给出例子了（绝对不是因为懒）。
知道了基本情况，我们想要更近一步地了解数据集，做出更深层次的判断，如计数、最大值最小值和平均值等，使用`describe()`函数即可。
```python
import pandas as pd
df=pd.read_csv("stockA.csv")
df.describe()
```
输出结果如下：
![thirdresult](https://i.postimg.cc/1zkx3VmY/image.png)
参数解释如下：count（计数）、mean（平均数）、std（方差）、min（最小值）、25%（四分之一分位数）、50%（二分之一分位数）、75%（四分之三分位数）、max（最大值）。
### 缺失值处理
在原始数据采集过程中，由于传感器或网络等问题，不可避免地会存在数据缺失的问题，数据源对于我们获取结果是最基础的一步，因此我们需要对数据进行合理的处理，才能使得结果较为准确。
#### 缺失值检查
在Python中，缺失值一般以NaN表示，读者有时候打开Excel文件可以看到一些单元格显示NaN，那些就是缺失值。
```python
import pandas as pd
df2=pd.read_csv("stockA.csv")
print(df2.isnull())
```
然后我们可以看到以下结果（这里因为我删除了一个数据作例子，读者显示的应该全是“False”的），当为空时显示为“True”，否则为“False”，其显示清晰明了地让我们知道有哪些数据是空的，非常方便。
![forthresult](https://i.postimg.cc/HLccgzSN/2025-03-28-121141.png)
我们还可以结合sum()函数得知缺失值的数量`print(df2.isnull().sum())`。
#### 缺失值删除
当缺失数据较多且重要程度不高时，我们可以直接使用`dropna()`方法删除这些没有价值的数据。
```python
import pandas as pd
df=pd.DataFrame({'column1':[None,2,3,4,None],'column2':[1,2,3,None,None],'colum3':[None,2,3,4,5],'column4':[None,None,None,None,None],'column5':[1,2,3,4,5]})
df.dropna()
```
运行后我们可以发现所有带有`None`的**行或列**都被删除了，实际情况我们大多数时候是要保留不为空的单元格的，只有当整行为空时才删除比较符合大多数需求。为实现这一需求，我们可以设置`dropna()`的参数`how`为`all`，同时可以设置`axis`参数来指定行或列。
```python
#续上
#当整行为空时，删除整行
df.dropna(how='all', axis=0)
#当整列为空时，删除整列
df.dropna(how='all', axis=1)
```
而设置`how='any'`与`axis`参数的值可以指定当**行或列**中有一个为空时删除该**行或列**。
#### 缺失值替换/填充
除了可以对数据中的缺失值进行删除以外，还可以进行替换和填充操作，有均值填补法、近邻填补法、插值填补法等。这里我们继续用缺失值删除小节的df作为例子。
首先，我们可以利用各列值的均值作为参数填充入空值中，即`df.fillna(df.mean())`，其次是近邻填补法，利用缺失值后面的数据进行填充：`df.fillna(method='bfill')`，利用缺失值前面的数据进行填充：`df.fillna(method='ffill')`，这两种是表常用的方法，请读者动手尝试一下。
常用方法举例补充：利用二次多项式插值法或三次样条插值法对column4列进行填充
```python
#使用order指定多项式幂次数，method指定方法，interpolate方法读者可自行查找
df['column4'].interpolate(method="polynomial",order=2)
#利用一个三次多项式逼近原目标函数，然后求解该三次多项式的极小点来作为原目标函数的极近似小点
df['column4'].interpolate(method="spline",order=3)
```
### 重复值处理
在数据采集过程中，有时会存在对同一个数据进行多次采集的情况，重复值的存在有可能导致数据集的各项数据偏离其所表达的信息，如平均值可能会偏大偏小等问题，因此对重复数据进行处理是十分必要的。
初步入门的话我们一般用到两个函数：`duplicated()`和`drop_duplicates()`。
'duplicated()'默认判断全部列中是否全部重复并返回布尔类型值。完全没有重复的行，返回值为False，有重复的行，第一次出现重复的那一行返回False，其余返回True。
'drop_duplicates()'默认判断全部列，删除冗余的所有行。
这里给到一个例子给读者去尝试一下:
```python
import pandas as pd
df=pd.DataFrame({'column1':[None,1,3,4,None],'column2':[1,2,3,None,None],'colum3':[None,2,3,4,5],'column4':[None,None,None,None,None],'column5':[1,2,3,4,5],'column6':[None,1,3,4,None]})
```
### 异常值的检测与处理
异常值这个概念实在是太抽象了，每一个值都可以是异常值，根据需求的不同异常值也不同。在数据分析中，异常值是指超出或低于正常范围的值，比如说年龄1000岁，体重为-100kg，人的身高50米等。本节将介绍如何处理这样的异常值数据。
#### 检测异常值
异常值的检测主要有两种方法，判断数据范围(query方法)和箱型图(boxplot方法)。
本节使用以下例子，没有明说则默认为该例子。
```python
import pandas as pd
df=pd.DataFrame({'名字':["小明","小红","小天","小刚","小芳","小美"],'年龄':[20,30,24,-2,43,23]})
df
```
在本例子中，首先使用pandas库中的query方法查询数据中是否有异常值，然后通过boxplot方法检测异常值。
```python
import pandas as pd
import matplotlib.pyplot as plt
#使用query查询数据中是否有异常值
print(df.query("年龄<1"))
#使用boxplot方法检测
plt.boxplot(df['年龄'])
```
结果如图所示
![fivethresult](https://i.postimg.cc/fLkBX7c9/image.png)
我们可以看到，数据中索引为3的值为异常值，箱型图中有两个偏离的比较远的点，如果学习过统计学概论可能会知道，这两个点很有可能就是异常值，因为其偏离平均值实在是太远了，但是从实际角度来说，只有小于0的那个数据是异常值。
#### 处理异常值
在数据分析过程中对异常值的处理通常包括三种常见的方法：一是直接删除它，最为简单粗暴的方法；二是当成缺失值处理，用某个值进行填充；三是当成特殊情况进行分析，研究其出现的原因。
第二种方法在上述有所展示，这里不再赘述，同时第三种方法是要分析者去研究，不太好用代码展示，因此，这里仅展示删除异常值，使用`drop()`方法实现，代码及结果如下：
```python
print("查看有无异常值:")
print(df.query("年龄<1"))
print("\n删除异常值:")
#index参数指定索引，axis参数“0”指定行，“1”指定列
df1=df.drop(index=3,axis=0)
print(df1)
```
![sixthresult](https://i.postimg.cc/43vzfJSS/image.png)
### 数据类型转换
不知读者在学习Python有没有学过，如果有也别跳过本节，因为本节使用的属性或函数是NumPy/Pandas特有的。本节介绍数据类型的检查及转换方法，主要使用`dtype`属性和`astype`函数。
#### 数据类型检查
首先使用arange方法创建数组arr，然后通过打印arr数据的`dtype`属性查看数据的数据类型，代码及运行结果如下：
```python
import numpy as np
arr1=np.arange(1,10,2)
print("arr1数组：",arr1)
print("arr1的数据类型为：",arr1.dtype)
arr2=np.arange(0,1,0.2)
print("arr2数据：",arr2)
print("arr2的数据类型为：",arr2.dtype)
```
![seventhresult](https://i.postimg.cc/HW6FWHGn/image.png)
#### 数据类型转换
首先使用arange方法创建一维浮点数组arr1，然后将arr1数据的数据类型转换为64位整型。代码及运行结果如下：
```python
import numpy as np
arr=np.arange(1,3,0.5)
print("arr数组为：",arr,"arr的数据类型为：",arr.dtype)
#将arr中的数据强制转换为整型
arr1=arr.astype(np.int64)
print("arr转换以后为：",arr1,"arr的数据类型为：",arr1.dtype)
```
![eighthresult](https://i.postimg.cc/5Nw7YMT8/image.png)
### 索引设置
索引用于加速数据检索，其作用相当于图书目录，我们可以根据目录中的页码快速找到对应的内容。这里额外提一嘴，就当作者自言自语，这些主要是数据库的内容，索引虽然可以提高查询速度，但是会降低删除和增加内容的速度，为什么呢，因为索引可以避免全表扫描，可以将O(n)的查询复杂度降低到O(logn)，但是其在修改操作时会写入放大，假设一个表中有N个索引，那每次数据修改实际上需要执行N+1次写入（数据+所有索引）。
#### 索引的设置、更改、重命名
我们可以通过设置Series方法中的参数index来设置索引，假如我们认为数据集中的索引不符合我们的需求，同时数据集中的一列符合我们的需求，可以使用`set_index()`函数来指定某一字段为索引，代码及结果如下：
```python
import pandas as pd
data=[[1,'a',False],[2,'b',True],[3,'c',False]]
columns=['A','B','C']
index=['X','Y','Z']
df=pd.DataFrame(data=data,columns=columns)
print("未设置索引前的表：\n",df)
#设置索引
df1=pd.DataFrame(data=data,columns=columns,index=index)
print("\n设置索引后的表：\n",df1)
#更改索引
df2=df.set_index('A')
print("\n更改索引后的表\n",df2)
```
![ninthresult](https://i.postimg.cc/W3z06GQP/image.png)
#### 重命名索引
在设置索引过程中，除了可以将数据中某一列设置为索引外，还可以对索引重命名，本节介绍对索引重命名的方法，函数`reindex()`。这里作者引用书中的例子进行说明。代码及结果如下：
```python
import pandas as pd
data=[[123,113,109],[45,23,90],[138,128,98]]
index=['stu1','stu2','stu5']
columns=['语文','英语','数学']
df=pd.DataFrame(data=data,columns=columns,index=index)
print("原表为：\n",df)
df1=df.reindex(index=['stu1','stu2','stu3','stu4','stu5'],columns=['语文','物理','数学','英语'])
print("\n重命名索引后的表为：\n",df1)
```
![tenthresult](https://i.postimg.cc/zDg3K2Vk/image.png)
### 其他常用预处理方法
#### 大小写转换
读者在学习Python后应该立刻反应过来了，使用`lower()`方法和`upper()`方法，是的，完全正确！所以这里只给出几个需要注意的点：
1. 这两个方法不会修改原始字符串，而是返回一个新的字符串，这是因为字符串在Python中是不可变的。
2. 在Pandas中，如果需要对DataFrame或Series中的字符串进行大小写转换，可以使用`.str.upper()`或`.str.lower()`方法。
3. 如果需要进行频繁的大小写转换，可以考虑使用如正则表达式（这里开个坑，以后详写）的方法来优化性能。
#### 数据的修改、替换和删除
第一章我们提到过对表数据的操作，但是不够详细，现在我们来详细讲解一下。
## 结语
希望通过本章学习，读者能够掌握查看数据基本信息的方法，对数据中缺失值与重复值的处理方法等内容。