## 导入数据
### 导入Excel表格数据文件
Excel文件有两种格式，分别为xls和xlsx格式，这两种格式都可以用Python的pandas模块的read_excel方法导入。返回结果为DataFrame，DataFrame的一列对应着Excel的一列。
```python
import pandas as pd
#普通导入
df1=pd.read_excel("path/filename.xlsx")
#使用index_col参数指定excel文件中的第一列作为行索引
df2=pd.read_excel("path/filename.xlsx", index_col=0)
#使用nrows导入前5行
df3=pd.read_excel("path/filename.xlsx", nrows=5)
#设置字段名，默认字段名为第一行，设置为None则为以0开始的序列
df4=pd.read_excel("path/filename.xlsx", header=None)
#使用name参数指定字段名
df5=pd.read_excel("path/filename.xlsx", header=None, names=['A', 'B', 'C', 'D']
#使用usecol参数导入指定列
df6=pd.read_excel("path/filename.xlsx", header=None, names=['A', 'B', 'C', 'D'], usecols=[1,3])
```
### 导入CSV格式数据
CSV是一种用分隔符分割的文件结构。不知读者是否参加过数学建模之类的竞赛，对于巨量数据主办方提供的多数是CSV文件，很少见是Excel文件，明明Excel这么常见又功能丰富，为什么不用Excel呢？那是因为Excel文件在存放巨量数据时会占用极大的空间，导入时会占用极大内存，而CSV作为纯文本文件，导入较为简便，因此巨量数据通常采用CSV格式。该格式可以用Python的pandas模块的read_csv方法实现。
```python
import pandas as pd
#sep参数表示要导入csv文件的分隔符，默认为半角逗号，encoding参数指定文件的编码，常用有utf-8和gbk
#什么是半角逗号？一般来说英文输入法的逗号就是半角逗号，中文输入法的是全角逗号。
df1=pd.read_csv("path/filename.csv", sep=",", encoding="gbk")
#使用nrows参数导入前3行
df2=pd.read_csv("path/filename.csv", sep=",", encoding="gbk", nrows=3)
#使用usecols参数导入指定列
df3=pd.read_csv("path/filename.csv", sep=",", encoding="gbk", usecols=[1,3])
#设置表头（字段名），默认字段名为第一行
df4=pd.read_csv("path/filename.csv", sep=",", encoding="gbk", names=['ni', 'hao', 'a'])
```
### 导入JSON格式数据
JSON是一种轻量级的数据交换格式，容易阅读也容易被机器扫描。JSON文件实际存储的是一个JSON对象或一个JSON数组，其由多个键值对组成，类似于Python的数据字典；而JSON数组由多个JSON对象组成，类似于Python的列表。
JSON数组的例子如下：
```json
[
    {
        "id": "1",
        "name": "kim",
        "age": "13"
    },
    {
       "id": "2",
       "name": "jimmy",
       "age": "16"
    },
]
```
其导入方式是使用pandas模块中的read_json方法导入。
```python
import pandas as pd
json1=pd.read_json("path/filename.json")
```
### 导入txt格式数据
相信txt读者都不陌生，我们可以使用pandas模块中的read_table方法进行导入，其参数和用法与read_csv方法类似。
```python
#假设字段之间用空格隔开，因此不需要用sep参数
import pandas as pd
txt1=pd.read_table("path/filename.txt")
```
### 导入爬取的网络数据
在Python数据分析当中，除了导入本地文件和数据库中的数据，还有一类随处可见，非常重要的数据，即网络数据。下面我将会举个例子来说明如何导入爬取的数据，请跟着作者一步一步来。
例一、爬取A股公司净利润排行榜
这里我们使用中商情报网的网页[A股上市公司名单](https://s.askci.com/stock/a/)进行爬取，中商情报网(ASKCI Consulting Co., Ltd)是一家提供市场研究和企业综合咨询服务的第三方研究机构专业，提供大量的商业和市场数据，包括企业信息、行业分析、市场报告、市场调研等内容。有兴趣的可以去了解一下。
现在，我们打开网页，可以看到有三个很明显的表格，这里我们爬取中间那个“A股公司净利润排行榜(2023年)”。
![threecolumns](https://i.postimg.cc/5tZpKP2g/image.png)
这里有三个表格，pandas模块中的read_html()方法十分便利，无需编写爬虫，只需要编写以下简单的几行代码即可爬取，后面作者会开一个爬虫栏目，read_html方法其实也调用了些爬虫库的方法，这里就不展开了。代码和结果如下：
```python
import pandas as pd
url="https://s.askci.com/stock/a/"
df=pd.read_html(url)[1]
print(df)
```
![result1](https://i.postimg.cc/9ftzs0Wk/image.png)
这里介绍以下read_html()方法。在使用该方法前，需要确定网页表格是否为table标签，我们可以用鼠标对准表格，点击鼠标“右键”，点击检查，查看是否为table标签，如图所示
![istable?](https://i.postimg.cc/5yqV2Yrc/2025-03-23-133057.png)
read_html()常用的参数有：
1. io：字符串，文件路径，也可以是url，当网址不接受https时我们可以去掉其中的“s”再进行爬取。
2. header：指定列标题所在行。
3. index_col：指定行标题所在列。

在爬取完之后我们想要保存数据到本地，那么我们就需要输出这个表格，这里作者简单介绍最常用的两种输出：csv格式数据输出，xlsx格式数据输出。
```python
df.to_csv("stockA.csv", encoding="utf-8")
df.to_excel("stockA.xlsx", encoding="utf-8")
```
运行上述代码后，我们可以在jupyter的homepage中看到输出的两个表格
![dataframeresult](https://i.postimg.cc/gkWMVBxH/image.png)
这里直接点击可能出错，使用记事本之类的软件打开即可。

to_csv常用参数有
path_or_buf：指定输出文件的路径或缓冲区对象。这是必需的参数
sep：字段分隔符，默认是半角逗号
index：布尔值，指定是否将DataFrame的行索引写入文件， 默认为True
header：布尔值，指定是否将列名（header）写入文件， 默认为True
mode：类似Python的文件打开模式， 默认是'w'（写模式）
encoding：指定输出文件的编码，默认通常是'utf-8'

to_excel常用的参数有
path_or_buf：指定输出文件的路径或ExcelWriter对象。这是必需的参数。
sheet_name：指定写入的工作表名称，默认是'Sheet1'。
index：布尔值，指定是否将DataFrame的行索引写入Excel文件， 默认为True。
header：布尔值，指定是否将列名（header）写入Excel文件， 默认为True。
startrow：指定开始写入的行号，默认是0（第一行）。
startcol：指定开始写入的列号，默认是0（第一列）。

这时候如果我们只想导出前十行，该怎么办呢？请回想一下第一章最后那张表格，表格中的head方法可以实现我们的需求，只需要添加`df1=df.head(10)`并修改下参数即可。

### 尾声
好，那么第二章节就这样愉快地结束了，不知您掌握了多少，学习是否愉快呢？下一章将会讲解**数据预处理**，敬请期待...

### 彩蛋
可能有些读者会说，列这么多方法出来记不住啊，作者的本意不是单纯的列出让您去记，而是为您留个印象，代码方法这么多我们不可能全部都记住，有了印象我们可以在遇到问题时意识到该使用哪方面的知识去解决，知道了相关的知识就去找相关的方法，而不是盲目地去搜索，因此作者认为这些方法是没必要去记忆的。